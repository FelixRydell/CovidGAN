# CovidGAN
Based on limited x-ray image data, we generate additional data and use it for training a neural network to give covid diagnosis


We investigate how generative adverserial networks can be used in the field of medicine. More specifically, in the beginning of a new pandemic, there will always be a lack of data. It turns out that detection and severity of COVID-19 can be diagnosed through X-ray images of the patients lung with good accuracy. Hence there is interest in classifying the COVID-19 infected chest X-rays. Training an neural network to detect such patterns in images requires a lot of data. If one only has access to a limit supply of data, one could remedy this by generating new data using a generative adversarial network. We chose 331 COVID-19 X-ray images of lungs and 601 normal lung images for our experiment. We then train a conditional generative adverserial network to generate a bigger set of data, so that we have 1000 COVID-19 images and 1000 normal ones. We compare the results from transfer learning of the last layer of a VGG16 network with both the small and bigger dataset that we have generated. For both trainings we use the same validation set of 72 COVID-19 images and 120 normal images. The fact that we choose specifically 331/601 samples to start with is to recreate the experiment of 'Covidgan: data augmentation using auxiliary classifier for improved covid-19 detection' by Waheed et. al.

We follow 'Conditional gan (cgan) in pytorch and tensorflow' by Sharma for our Tensorflow and Pytorch architectures. Our results are that the accuracy increased from 0.958 to 0.974 in validation accuracy with PyTorch and to 0.98 with Tensorflow, when the additionally generated data is used. 
